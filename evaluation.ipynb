{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read the log file in output folder and generate a csv file\n",
    "# import os\n",
    "# import sys\n",
    "# import csv\n",
    "# import re\n",
    "# import datetime\n",
    "\n",
    "# # Specify the path to the log file\n",
    "# # find the log file in the output folder\n",
    "# output_folder = \"output\"\n",
    "# log_files = []\n",
    "# for root, dirs, files in os.walk(output_folder):\n",
    "#     for file in files:\n",
    "#         if \".inprogress\" in file:\n",
    "#             log_files.append(os.path.join(root, file))\n",
    "# if len(log_files) == 0:\n",
    "#     print(\"No log file found in the output folder\")\n",
    "#     sys.exit(1)\n",
    "# # get the latest log file\n",
    "# log_file_path = log_files[0]\n",
    "# for log_file in log_files:\n",
    "#     if os.path.getmtime(log_file) > os.path.getmtime(log_file_path):\n",
    "#         log_file_path = log_file\n",
    "# print(\"log file path: \", log_file_path)\n",
    "\n",
    "# # Specify the path to the output CSV file\n",
    "# csv_file_path = \"output/log.csv\"\n",
    "\n",
    "# # Open the log file for reading\n",
    "# with open(log_file_path, \"r\") as log_file:\n",
    "#     # Read the contents of the log file\n",
    "#     log_contents = log_file.read().splitlines()\n",
    "\n",
    "# # Open the CSV file for writing\n",
    "# with open(csv_file_path, \"w\", newline=\"\") as csv_file:\n",
    "#     # Create a CSV writer object\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "\n",
    "#     # Write the header row\n",
    "#     csv_writer.writerow([\"c_custkey\", \"c_name\", \"c_acctbal\", \"c_address\", \"n_name\", \"c_phone\", \"c_comment\", \"deltaRevenue\", \"revenue\"])\n",
    "    \n",
    "#     # Write each line in the log file into the CSV file\n",
    "#     # change the delimeter from \"|\" to \",\"\n",
    "#     for line in log_contents:\n",
    "#         # Split the line into fields\n",
    "#         fields = line.split(\"|\")\n",
    "#         # Write the fields into the CSV file\n",
    "#         csv_writer.writerow(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the mysql query result\n",
    "mysql_csv_path = \"mysql_test/queryResult_mysql.csv\"\n",
    "flink_csv_path = \"output/log.csv\"\n",
    "\n",
    "# read csv file\n",
    "mysql_df = pd.read_csv(mysql_csv_path)\n",
    "flink_df = pd.read_csv(flink_csv_path)\n",
    "\n",
    "mysql_df = mysql_df[[\"c_custkey\", \"revenue\"]]\n",
    "flink_df = flink_df[[\"c_custkey\", \"revenue\"]]\n",
    "\n",
    "join_df = pd.merge(mysql_df, flink_df, on=\"c_custkey\", how=\"inner\", suffixes=(\"_mysql\", \"_flink\"))\n",
    "join_df[\"diff\"] = join_df[\"revenue_mysql\"] - join_df[\"revenue_flink\"]\n",
    "consistent = join_df[join_df[\"diff\"] == 0]\n",
    "inconsistent = join_df[join_df[\"diff\"] != 0]\n",
    "\n",
    "all_custkey = mysql_df[\"c_custkey\"].unique()\n",
    "missing_custkey = [custkey for custkey in all_custkey if custkey not in join_df[\"c_custkey\"].unique()]\n",
    "consistent_custkey = consistent[\"c_custkey\"].unique()\n",
    "inconsistent_custkey = [custkey for custkey in all_custkey if custkey not in consistent_custkey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consistent ratio:  0.7117794486215538\n",
      "inconsistent ratio:  0.2882205513784461\n",
      "missing ratio:  0.09774436090225563\n"
     ]
    }
   ],
   "source": [
    "# calculate ratio of consistent and inconsistent\n",
    "total_custkey = len(all_custkey)\n",
    "consistent_ratio = len(consistent_custkey) / total_custkey\n",
    "inconsistent_ratio = len(inconsistent_custkey) / total_custkey\n",
    "missing_ratio = len(missing_custkey) / total_custkey\n",
    "print(\"consistent ratio: \", consistent_ratio)\n",
    "print(\"inconsistent ratio: \", inconsistent_ratio)\n",
    "print(\"missing ratio: \", missing_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_custkey</th>\n",
       "      <th>revenue_mysql</th>\n",
       "      <th>revenue_flink</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>679</td>\n",
       "      <td>378211.3252</td>\n",
       "      <td>378211.3252</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1201</td>\n",
       "      <td>374331.5340</td>\n",
       "      <td>374331.5340</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>422</td>\n",
       "      <td>366451.0126</td>\n",
       "      <td>366451.0126</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>334</td>\n",
       "      <td>360370.7550</td>\n",
       "      <td>360370.7550</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>805</td>\n",
       "      <td>359448.9036</td>\n",
       "      <td>359448.9036</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>368</td>\n",
       "      <td>5544.4850</td>\n",
       "      <td>5544.4850</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>931</td>\n",
       "      <td>5288.0544</td>\n",
       "      <td>5288.0544</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>823</td>\n",
       "      <td>5092.6080</td>\n",
       "      <td>5092.6080</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>733</td>\n",
       "      <td>1691.8360</td>\n",
       "      <td>1691.8360</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>1463</td>\n",
       "      <td>1550.5380</td>\n",
       "      <td>1550.5380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      c_custkey  revenue_mysql  revenue_flink  diff\n",
       "9           679    378211.3252    378211.3252   0.0\n",
       "18         1201    374331.5340    374331.5340   0.0\n",
       "25          422    366451.0126    366451.0126   0.0\n",
       "32          334    360370.7550    360370.7550   0.0\n",
       "40          805    359448.9036    359448.9036   0.0\n",
       "...         ...            ...            ...   ...\n",
       "1144        368      5544.4850      5544.4850   0.0\n",
       "1145        931      5288.0544      5288.0544   0.0\n",
       "1146        823      5092.6080      5092.6080   0.0\n",
       "1147        733      1691.8360      1691.8360   0.0\n",
       "1148       1463      1550.5380      1550.5380   0.0\n",
       "\n",
       "[362 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_less_than_10 = join_df[join_df[\"diff\"]/join_df['revenue_mysql'].abs() < 0.01]\n",
    "diff_less_than_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "# folder = \"src/main/resources/data\"\n",
    "folder = \"tpch_datasets/data_sf0.8\"\n",
    "\n",
    "# file needs update operations (in dependent order)\n",
    "files = ['nation.tbl', 'customer.tbl', 'orders.tbl', 'lineitem.tbl']\n",
    "\n",
    "fieldnames = {\n",
    "    \"nation\": [\"N_NATIONKEY\", \"N_NAME\", \"N_REGIONKEY\", \"N_COMMENT\"],\n",
    "    \"customer\": [\"C_CUSTKEY\", \"C_NAME\", \"C_ADDRESS\", \"C_NATIONKEY\", \"C_PHONE\", \"C_ACCTBAL\", \"C_MKTSEGMENT\", \"C_COMMENT\"],\n",
    "    \"orders\": [\"O_ORDERKEY\", \"O_CUSTKEY\", \"O_ORDERSTATUS\", \"O_TOTALPRICE\", \"O_ORDERDATE\", \"O_ORDERPRIORITY\", \"O_CLERK\", \"O_SHIPPRIORITY\", \"O_COMMENT\"],\n",
    "    \"lineitem\": [\"L_ORDERKEY\", \"L_PARTKEY\", \"L_SUPPKEY\", \"L_LINENUMBER\", \"L_QUANTITY\", \"L_EXTENDEDPRICE\", \"L_DISCOUNT\", \"L_TAX\", \"L_RETURNFLAG\", \"L_LINESTATUS\", \"L_SHIPDATE\", \"L_COMMITDATE\", \"L_RECEIPTDATE\", \"L_SHIPINSTRUCT\", \"L_SHIPMODE\", \"L_COMMENT\"]\n",
    "}\n",
    "\n",
    "for file in files:\n",
    "    # Open the raw data file for reading\n",
    "    with open(os.path.join(folder, file), \"r\") as raw_data_file:\n",
    "        # Read the contents of the log file\n",
    "        file_contents = raw_data_file.read().splitlines()\n",
    "\n",
    "    # Open the CSV file for writing\n",
    "    with open(folder+\"/\"+file.replace(\".tbl\",\".csv\"), \"w\", newline=\"\") as csv_file:\n",
    "        # Create a CSV writer object\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "\n",
    "        # Write the header row\n",
    "        csv_writer.writerow(fieldnames[file.split(\".\")[0]]) # remove the file extension\n",
    "        \n",
    "        # Write each line in the log file into the CSV file\n",
    "        # change the delimeter from \"|\" to \",\"\n",
    "        for line in file_contents:\n",
    "            # Split the line into fields\n",
    "            fields = line.split(\"|\")\n",
    "            # Write the fields into the CSV file\n",
    "            csv_writer.writerow(fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nation.csv\n",
      "consistent:  25\n",
      "inconsistent:  0\n",
      "missing:  0\n",
      "customer.csv\n",
      "consistent:  120000\n",
      "inconsistent:  0\n",
      "missing:  30000\n",
      "orders.csv\n",
      "consistent:  9506076\n",
      "inconsistent:  10492239\n",
      "missing:  -18498315\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m join_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(table_s08, table_s10, on\u001b[38;5;241m=\u001b[39mpk, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sf08\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sf10\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     21\u001b[0m join_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m join_df[compare_field\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sf08\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m join_df[compare_field\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sf10\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 22\u001b[0m consistent \u001b[38;5;241m=\u001b[39m \u001b[43mjoin_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mjoin_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdiff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\n\u001b[1;32m     23\u001b[0m inconsistent \u001b[38;5;241m=\u001b[39m join_df[join_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(file)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:4155\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   4154\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 4155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:688\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    681\u001b[0m         indexer,\n\u001b[1;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n\u001b[1;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/internals/blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/array_algos/take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[1;32m    161\u001b[0m )\n\u001b[0;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[1;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 对比sf0.8和sf1.0的数据，看是否一致\n",
    "# folder = \"tpch_datasets/data_sf1.0\"\n",
    "files = ['nation.csv', 'customer.csv', 'orders.csv', 'lineitem.csv']\n",
    "fieldnames = {\n",
    "    \"nation\": [\"N_NATIONKEY\", \"N_NAME\", \"N_REGIONKEY\", \"N_COMMENT\"],\n",
    "    \"customer\": [\"C_CUSTKEY\", \"C_NAME\", \"C_ADDRESS\", \"C_NATIONKEY\", \"C_PHONE\", \"C_ACCTBAL\", \"C_MKTSEGMENT\", \"C_COMMENT\"],\n",
    "    \"orders\": [\"O_ORDERKEY\", \"O_CUSTKEY\", \"O_ORDERSTATUS\", \"O_TOTALPRICE\", \"O_ORDERDATE\", \"O_ORDERPRIORITY\", \"O_CLERK\", \"O_SHIPPRIORITY\", \"O_COMMENT\"],\n",
    "    \"lineitem\": [\"L_ORDERKEY\", \"L_PARTKEY\", \"L_SUPPKEY\", \"L_LINENUMBER\", \"L_QUANTITY\", \"L_EXTENDEDPRICE\", \"L_DISCOUNT\", \"L_TAX\", \"L_RETURNFLAG\", \"L_LINESTATUS\", \"L_SHIPDATE\", \"L_COMMITDATE\", \"L_RECEIPTDATE\", \"L_SHIPINSTRUCT\", \"L_SHIPMODE\", \"L_COMMENT\"]\n",
    "}\n",
    "\n",
    "for file in files:\n",
    "    table_s08 = pd.read_csv(f\"tpch_datasets/data_sf0.8/{file}\")\n",
    "    table_s10 = pd.read_csv(f\"tpch_datasets/data_sf1.0/{file}\")\n",
    "    \n",
    "    pk = fieldnames[file.split(\".\")[0]][0]\n",
    "    compare_field = fieldnames[file.split(\".\")[0]][1]\n",
    "    join_df = pd.merge(table_s08, table_s10, on=pk, how=\"inner\", suffixes=(\"_sf08\", \"_sf10\"))\n",
    "    \n",
    "    join_df[\"diff\"] = join_df[compare_field+\"_sf08\"] == join_df[compare_field+\"_sf10\"]\n",
    "    consistent = join_df[join_df[\"diff\"] == True]\n",
    "    inconsistent = join_df[join_df[\"diff\"] == False]\n",
    "    \n",
    "    print(file)\n",
    "    print(\"consistent: \", len(consistent))\n",
    "    print(\"inconsistent: \", len(inconsistent))\n",
    "    print(\"missing: \", len(table_s10) - len(consistent) - len(inconsistent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
